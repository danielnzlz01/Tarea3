{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {
        "id": "ILC8B88PGVpi"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "id": "CnwhfL3NUaag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('D:\\Descargas\\IMDB Dataset.csv')\n",
        "\n",
        "data['review'] = data['review'].str.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Negation(sentence):\t\n",
        "  temp = int(0)\n",
        "  for i in range(len(sentence)):\n",
        "      if sentence[i-1] in ['not',\"n't\"]:\n",
        "          antonyms = []\n",
        "          for syn in wordnet.synsets(sentence[i]):\n",
        "              syns = wordnet.synsets(sentence[i])\n",
        "              w1 = syns[0].name()\n",
        "              temp = 0\n",
        "              for l in syn.lemmas():\n",
        "                  if l.antonyms():\n",
        "                      antonyms.append(l.antonyms()[0].name())\n",
        "              max_dissimilarity = 0\n",
        "              for ant in antonyms:\n",
        "                  syns = wordnet.synsets(ant)\n",
        "                  w2 = syns[0].name()\n",
        "                  syns = wordnet.synsets(sentence[i])\n",
        "                  w1 = syns[0].name()\n",
        "                  word1 = wordnet.synset(w1)\n",
        "                  word2 = wordnet.synset(w2)\n",
        "                  if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):\n",
        "                      temp = 1 - word1.wup_similarity(word2)\n",
        "                  if temp>max_dissimilarity:\n",
        "                      max_dissimilarity = temp\n",
        "                      antonym_max = ant\n",
        "                      sentence[i] = antonym_max\n",
        "                      sentence[i-1] = ''\n",
        "  while '' in sentence:\n",
        "      sentence.remove('')\n",
        "  return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'did', 'dislike', 'you']\n"
          ]
        }
      ],
      "source": [
        "sentence = word_tokenize(\"i didn't like you\")\n",
        "#print(word_tokenize(\"he doesn't like you\"))\n",
        "print(Negation(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fin ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>this show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>if you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  one of the other reviewers has mentioned that ...  positive\n",
              "1  a wonderful little production. <br /><br />the...  positive\n",
              "2  i thought this was a wonderful way to spend ti...  positive\n",
              "3  basically there's a family where a little boy ...  negative\n",
              "4  petter mattei's \"love in the time of money\" is...  positive\n",
              "5  probably my all-time favorite movie, a story o...  positive\n",
              "6  i sure would like to see a resurrection of a u...  positive\n",
              "7  this show was an amazing, fresh & innovative i...  negative\n",
              "8  encouraged by the positive comments about this...  negative\n",
              "9  if you like original gut wrenching laughter yo...  positive"
            ]
          },
          "execution_count": 466,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prueba.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {},
      "outputs": [],
      "source": [
        "sincaracteres = prueba[\"review\"].apply(lambda cw : remove_tags(cw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "metadata": {},
      "outputs": [],
      "source": [
        "sincaracteres2 = []\n",
        "for i in range(len(sincaracteres)):\n",
        "    negado = []\n",
        "    for j in range(len(sincaracteres[i].split(\".\"))):\n",
        "        sent = Negation(word_tokenize(sincaracteres[i].split(\".\")[j]))\n",
        "        negado.append(sent)\n",
        "    sincaracteres2.append(negado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews2 = []\n",
        "for i in range(len(sincaracteres2)):\n",
        "    lista = []\n",
        "    for j in range(len(sincaracteres2[i])):\n",
        "        nueva = ' '.join(sincaracteres2[i][j])\n",
        "        lista.append(nueva)\n",
        "    lista2 = '.'.join(lista)\n",
        "    reviews2.append(lista2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviewsf = []\n",
        "for i in range(len(reviews2)):\n",
        "    reviews2[i] = reviews2[i].replace(\" '\", \"'\")\n",
        "    reviews2[i] = reviews2[i].replace(\" ,\", \",\")\n",
        "    reviews2[i] = reviews2[i].replace(\" n't\", \"n't\")\n",
        "    reviewsf.append(reviews2[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba[\"review\"] = reviewsf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "viejo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {
        "id": "V0oF19XKyi8E"
      },
      "outputs": [],
      "source": [
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "id": "O20xL-WtzODy"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(data):\n",
        "  data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "#def remove_tags(string):\n",
        "#    result = re.sub('<.*?>','',string)\n",
        "#    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "HehsxBu108xh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_25428\\2824813740.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
          ]
        }
      ],
      "source": [
        "data_without_stopwords = remove_stopwords(data)\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_25428\\2951378201.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data_without_stopwords2['clean_review'] = data_without_stopwords2['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
          ]
        }
      ],
      "source": [
        "data_without_stopwords2 = remove_stopwords(prueba)\n",
        "data_without_stopwords2['clean_review'] = data_without_stopwords2['review without stopwords']\n",
        "data_without_stopwords2['clean_review'] = data_without_stopwords2['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "H4JDXL8A3CSO",
        "outputId": "42fe31d7-2c6d-4efa-97b2-071855b81be2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
              "      <td>wonderful little production  the filming techn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy (jake) thinks zomb...</td>\n",
              "      <td>basically family little boy  jake  thinks zomb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "      <td>petter mattei s  love time money  visually stu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  one of the other reviewers has mentioned that ...  positive   \n",
              "1  a wonderful little production. <br /><br />the...  positive   \n",
              "2  i thought this was a wonderful way to spend ti...  positive   \n",
              "3  basically there's a family where a little boy ...  negative   \n",
              "4  petter mattei's \"love in the time of money\" is...  positive   \n",
              "\n",
              "                            review without stopwords  \\\n",
              "0  one reviewers mentioned watching just 1 oz epi...   \n",
              "1  wonderful little production. <br /><br />the f...   \n",
              "2  thought wonderful way spend time hot summer we...   \n",
              "3  basically family little boy (jake) thinks zomb...   \n",
              "4  petter mattei's \"love time money\" visually stu...   \n",
              "\n",
              "                                        clean_review  \n",
              "0  one reviewers mentioned watching just 1 oz epi...  \n",
              "1  wonderful little production  the filming techn...  \n",
              "2  thought wonderful way spend time hot summer we...  \n",
              "3  basically family little boy  jake  thinks zomb...  \n",
              "4  petter mattei s  love time money  visually stu...  "
            ]
          },
          "execution_count": 477,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_without_stopwords.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZFHtdni5mZE",
        "outputId": "c4a3e629-052b-497c-c97d-58b22ea525a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        one reviewers mentioned watching just 1 oz epi...\n",
              "1        wonderful little production  the filming techn...\n",
              "2        thought wonderful way spend time hot summer we...\n",
              "3        basically family little boy  jake  thinks zomb...\n",
              "4        petter mattei s  love time money  visually stu...\n",
              "                               ...                        \n",
              "49995    thought movie right good job  wasn t creative ...\n",
              "49996    bad plot  bad dialogue  bad acting  idiotic di...\n",
              "49997    catholic taught parochial elementary schools n...\n",
              "49998    going disagree previous comment side maltin on...\n",
              "49999    no one expects star trek movies high art  fans...\n",
              "Name: clean_review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 478,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews = data_without_stopwords['clean_review']\n",
        "reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        one reviewers mentioned watching just 1 oz epi...\n",
              "1        wonderful little production the filming techni...\n",
              "2        thought wonderful way spend time hot summer we...\n",
              "3        basically family little boy   jake   thinks zo...\n",
              "4        petter mattei s    love time money   visually ...\n",
              "                               ...                        \n",
              "49995    thought movie right good job it wasn t creativ...\n",
              "49996    bad plot  bad dialogue  bad acting  idiotic di...\n",
              "49997    catholic taught parochial elementary schools n...\n",
              "49998    going disagree previous comment side maltin on...\n",
              "49999    no one expects star trek movies high art  fans...\n",
              "Name: clean_review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 479,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviewsneg = data_without_stopwords2['clean_review']\n",
        "reviewsneg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "id": "fSMjGYrUU1jX"
      },
      "outputs": [],
      "source": [
        "reviews_list = []\n",
        "for i in range(len(reviews)):\n",
        "  reviews_list.append(reviews[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_list2 = []\n",
        "for i in range(len(reviewsneg)):\n",
        "  reviews_list2.append(reviewsneg[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "urgoMx7UaeJz"
      },
      "outputs": [],
      "source": [
        "sentiment = data_without_stopwords['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "tjY5K71YWVe4"
      },
      "outputs": [],
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqdMpZR0Wpg8",
        "outputId": "5275fe2d-3f29-45d3-f633-24513807a6ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 484,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "id": "fqkDtVPMYeeT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(reviews_list2, y, test_size=0.2, random_state = 45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8446f0TtQl-3",
        "outputId": "718e7ed2-d241-4fa2-fdaa-3137ee24b0d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "execution_count": 487,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "id": "ujoI8P64P12P"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer2 = Tokenizer(num_words=5000)\n",
        "tokenizer2.fit_on_texts(X_train2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {
        "id": "0rZPh61RP5gH"
      },
      "outputs": [],
      "source": [
        "words_to_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {},
      "outputs": [],
      "source": [
        "words_to_index2 = tokenizer2.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj1lFsRPP7G7",
        "outputId": "5355b6d7-e625-45c9-a60f-cdc81cf7fcf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "95419"
            ]
          },
          "execution_count": 492,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(words_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 493,
      "metadata": {
        "id": "4cfT3r4nc5GE"
      },
      "outputs": [],
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 494,
      "metadata": {
        "id": "S4QJe7iZeDC1"
      },
      "outputs": [],
      "source": [
        "word_to_vec_map = read_glove_vector('D:/Descargas/glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {
        "id": "_VF9U14qjjXw"
      },
      "outputs": [],
      "source": [
        "maxLen = 150\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 496,
      "metadata": {
        "id": "Am3MZl2fobDn"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 497,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_len2 = len(words_to_index2)\n",
        "embed_vector_len2 = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix2 = np.zeros((vocab_len2, embed_vector_len2))\n",
        "\n",
        "for word, index in words_to_index2.items():\n",
        "  embedding_vector2 = word_to_vec_map.get(word)\n",
        "  if embedding_vector2 is not None:\n",
        "    emb_matrix2[index, :] = embedding_vector2\n",
        "\n",
        "embedding_layer2 = Embedding(input_dim=vocab_len2, output_dim=embed_vector_len2, input_length=maxLen, weights = [emb_matrix2], trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 498,
      "metadata": {
        "id": "DlqxRxizpZRl"
      },
      "outputs": [],
      "source": [
        "# def imdb_rating(input_shape):\n",
        "\n",
        "#   X_indices = Input(input_shape)\n",
        "\n",
        "#   embeddings = embedding_layer(X_indices)\n",
        "\n",
        "#   X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "#   X = Dropout(0.6)(X)\n",
        "\n",
        "#   X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "#   X = Dropout(0.6)(X)\n",
        "\n",
        "#   X = LSTM(128)(X)\n",
        "\n",
        "#   X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "#   model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "#   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 499,
      "metadata": {
        "id": "L75PYl9Z2F1d"
      },
      "outputs": [],
      "source": [
        "def conv1d_model(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = Conv1D(512,3,activation='relu')(embeddings)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  X = Dropout(0.8)(X)\n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = GlobalMaxPooling1D()(X)\n",
        "\n",
        "  X = Dense(256, activation='relu')(X)\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv1d_model2(input_shape):\n",
        "\n",
        "  X_indices2 = Input(input_shape)\n",
        "\n",
        "  embeddings2 = embedding_layer2(X_indices2)\n",
        "\n",
        "  X2 = Conv1D(512,3,activation='relu')(embeddings2)\n",
        "  \n",
        "  X2 = MaxPooling1D(3)(X2)\n",
        "\n",
        "  X2 = Conv1D(256,3,activation='relu')(X2)\n",
        "  \n",
        "  X2 = MaxPooling1D(3)(X2)\n",
        "\n",
        "  X2 = Conv1D(256,3,activation='relu')(X2)\n",
        "  X2 = Dropout(0.8)(X2)\n",
        "  X2 = MaxPooling1D(3)(X2)\n",
        "\n",
        "  X2 = GlobalMaxPooling1D()(X2)\n",
        "\n",
        "  X2 = Dense(256, activation='relu')(X2)\n",
        "  X2 = Dense(1, activation='sigmoid')(X2)\n",
        "\n",
        "  model2 = Model(inputs=X_indices2, outputs=X2)\n",
        "\n",
        "  return model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 501,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeB6unmRpa2a",
        "outputId": "6987ca2e-bef8-427a-8f49-e5344b472d97"
      },
      "outputs": [],
      "source": [
        "# model = imdb_rating((maxLen,))\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 502,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppZiV3h3wH2",
        "outputId": "546fbe0e-93e5-410a-bb48-23f7fb18bd51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 150, 50)           4770950   \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 148, 512)          77312     \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPoolin  (None, 49, 512)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 47, 256)           393472    \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPoolin  (None, 15, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 13, 256)           196864    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 13, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPoolin  (None, 4, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_8 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,504,647\n",
            "Trainable params: 733,697\n",
            "Non-trainable params: 4,770,950\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1d = conv1d_model((maxLen,))\n",
        "model_1d.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 503,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, 150, 50)           4769850   \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 148, 512)          77312     \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPoolin  (None, 49, 512)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 47, 256)           393472    \n",
            "                                                                 \n",
            " max_pooling1d_28 (MaxPoolin  (None, 15, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 13, 256)           196864    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 13, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 4, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_9 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,503,547\n",
            "Trainable params: 733,697\n",
            "Non-trainable params: 4,769,850\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1d2 = conv1d_model2((maxLen,))\n",
        "model_1d2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 504,
      "metadata": {
        "id": "Z_ygaA18uv9Z"
      },
      "outputs": [],
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 505,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_indices2 = tokenizer2.texts_to_sequences(X_train2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 506,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSdM8mIMRRnM",
        "outputId": "bd312a8c-d0ad-4ad6-83b1-42c13328a528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 150)"
            ]
          },
          "execution_count": 506,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
        "X_train_indices.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 507,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 150)"
            ]
          },
          "execution_count": 507,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_indices2 = pad_sequences(X_train_indices2, maxlen=maxLen, padding='post')\n",
        "X_train_indices2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 508,
      "metadata": {
        "id": "UQ09l2WL4jhN"
      },
      "outputs": [],
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model_1d.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 509,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgAAjTim4o2E",
        "outputId": "a219a3c3-b574-44b1-9433-808f5a492495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 62s 98ms/step - loss: 0.5697 - accuracy: 0.6985\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 0.4646 - accuracy: 0.7818\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.4164 - accuracy: 0.8099\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 63s 100ms/step - loss: 0.3836 - accuracy: 0.8284\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 75s 119ms/step - loss: 0.3600 - accuracy: 0.8396\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 77s 124ms/step - loss: 0.3297 - accuracy: 0.8539\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.3076 - accuracy: 0.8675\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 71s 114ms/step - loss: 0.2853 - accuracy: 0.8790\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.2631 - accuracy: 0.8906\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 72s 115ms/step - loss: 0.2316 - accuracy: 0.9049\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 0.1986 - accuracy: 0.9211\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 78s 125ms/step - loss: 0.1647 - accuracy: 0.9368\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 80s 128ms/step - loss: 0.1289 - accuracy: 0.9514\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.1032 - accuracy: 0.9615\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.0793 - accuracy: 0.9717\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24cb17dee30>"
            ]
          },
          "execution_count": 509,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1d.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 64s 102ms/step - loss: 0.4960 - accuracy: 0.7501\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3671 - accuracy: 0.8353\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 108s 173ms/step - loss: 0.3262 - accuracy: 0.8581\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 95s 153ms/step - loss: 0.2805 - accuracy: 0.8812\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 87s 139ms/step - loss: 0.2349 - accuracy: 0.9025\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 74s 119ms/step - loss: 0.1963 - accuracy: 0.9202\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 0.1501 - accuracy: 0.9407\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 78s 124ms/step - loss: 0.1154 - accuracy: 0.9560\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 75s 120ms/step - loss: 0.0939 - accuracy: 0.9637\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.0764 - accuracy: 0.9718\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 64s 103ms/step - loss: 0.0647 - accuracy: 0.9759\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 64s 103ms/step - loss: 0.0608 - accuracy: 0.9769\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 0.0516 - accuracy: 0.9815\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.0509 - accuracy: 0.9815\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 82s 130ms/step - loss: 0.0487 - accuracy: 0.9819\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x24c994be080>"
            ]
          },
          "execution_count": 510,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adam2 = keras.optimizers.Adam(learning_rate = 0.001)\n",
        "model_1d2.compile(optimizer=adam2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_1d2.fit(X_train_indices2, Y_train2, batch_size=64, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {
        "id": "mwYyQk7_JvYg"
      },
      "outputs": [],
      "source": [
        "# adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "# model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZphzSinHwPO",
        "outputId": "baa9feb3-3f33-4a5d-da0d-f2ddfea4a475"
      },
      "outputs": [],
      "source": [
        "# model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 513,
      "metadata": {
        "id": "oVY1gYalXkO7"
      },
      "outputs": [],
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 514,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_indices2 = tokenizer2.texts_to_sequences(X_test2)\n",
        "\n",
        "X_test_indices2 = pad_sequences(X_test_indices2, maxlen=maxLen, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 515,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Y5fW-xszbc",
        "outputId": "19901712-3f09-4328-9f5f-9c82498fd97b"
      },
      "outputs": [],
      "source": [
        "# model.evaluate(X_test_indices, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 536,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EitDh0YpDo2e",
        "outputId": "810fb5e4-01e6-420a-c415-8a52a5ed9d81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 21ms/step - loss: 0.3733 - accuracy: 0.8308\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3732887804508209, 0.8307999968528748]"
            ]
          },
          "execution_count": 536,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1d.evaluate(X_test_indices, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 537,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 21ms/step - loss: 0.3975 - accuracy: 0.8319\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3974872827529907, 0.8319000005722046]"
            ]
          },
          "execution_count": 537,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1d2.evaluate(X_test_indices2, Y_test2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 518,
      "metadata": {
        "id": "-SKL-SzCs9e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model_1d.predict(X_test_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 519,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 8s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "preds2 = model_1d2.predict(X_test_indices2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 520,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "w_vyAiZZ-7hy",
        "outputId": "4448b915-6616-4be1-ef9e-9c1c1a95259f"
      },
      "outputs": [],
      "source": [
        "# n = np.random.randint(0,9999)\n",
        "\n",
        "# X_test[n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 521,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTtNGnSj0xJ9",
        "outputId": "777d729a-678f-426e-b8b0-bebd15eae1ca"
      },
      "outputs": [],
      "source": [
        "# if preds[n] > 0.5:\n",
        "#   print('predicted sentiment : positive')\n",
        "# else: \n",
        "#   print('precicted sentiment : negative')\n",
        "\n",
        "# if (Y_test[n] == 1):\n",
        "#   print('correct sentiment : positive')\n",
        "# else:\n",
        "#   print('correct sentiment : negative')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 522,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYeroDRh_GSQ",
        "outputId": "6e013c06-c66f-4339-91b6-03b21ca1e521"
      },
      "outputs": [],
      "source": [
        "# preds[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 523,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRX1lXzyAiCk",
        "outputId": "f5394567-7c33-43c9-d0e9-adda6dc5ef63"
      },
      "outputs": [],
      "source": [
        "# Y_test[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 524,
      "metadata": {
        "id": "vt4-cklo_IRl"
      },
      "outputs": [],
      "source": [
        "model_1d.save_weights('D:/Descargas/imdb_weights_con1vd.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 525,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1d2.save_weights('D:/Descargas/imdb_weights_con1vd.hdf5_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 526,
      "metadata": {
        "id": "wS9yTCwAzbvl"
      },
      "outputs": [],
      "source": [
        "reviews_list_idx = tokenizer.texts_to_sequences(reviews_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 527,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_list_idx2 = tokenizer2.texts_to_sequences(reviews_list2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 528,
      "metadata": {
        "id": "o5VqbyPE2JXs"
      },
      "outputs": [],
      "source": [
        "def add_score_predictions(data, reviews_list_idx):\n",
        "\n",
        "  data['sentiment score'] = 0\n",
        "\n",
        "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
        "\n",
        "  review_preds = model_1d.predict(reviews_list_idx)\n",
        "\n",
        "  data['sentiment score'] = review_preds\n",
        "\n",
        "  pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\n",
        "\n",
        "  data['predicted sentiment'] = 0\n",
        "\n",
        "  data['predicted sentiment'] = pred_sentiment\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 529,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_score_predictions2(data, reviews_list_idx):\n",
        "\n",
        "  data['sentiment score'] = 0\n",
        "\n",
        "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
        "\n",
        "  review_preds2 = model_1d2.predict(reviews_list_idx)\n",
        "\n",
        "  data['sentiment score'] = review_preds2\n",
        "\n",
        "  pred_sentiment2 = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds2)))\n",
        "\n",
        "  data['predicted sentiment'] = 0\n",
        "\n",
        "  data['predicted sentiment'] = pred_sentiment2\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 530,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataf1 = data.copy()\n",
        "dataf2 = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 531,
      "metadata": {
        "id": "M2SPaF7N3C3g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 37s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "dataf1 = add_score_predictions(dataf1, reviews_list_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 38s 24ms/step\n"
          ]
        }
      ],
      "source": [
        "dataf2 = add_score_predictions2(dataf2, reviews_list_idx2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 533,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>predicted sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>0.816103</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
              "      <td>wonderful little production  the filming techn...</td>\n",
              "      <td>0.982594</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>0.981700</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy (jake) thinks zomb...</td>\n",
              "      <td>basically family little boy  jake  thinks zomb...</td>\n",
              "      <td>0.557990</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "      <td>petter mattei s  love time money  visually stu...</td>\n",
              "      <td>0.978383</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>i thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought movie right good job. wasn't creative ...</td>\n",
              "      <td>thought movie right good job  wasn t creative ...</td>\n",
              "      <td>0.973569</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
              "      <td>0.006047</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>i am a catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>0.255125</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>i'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>0.224971</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "      <td>no one expects star trek movies high art, fans...</td>\n",
              "      <td>no one expects star trek movies high art  fans...</td>\n",
              "      <td>0.192421</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment  \\\n",
              "0      one of the other reviewers has mentioned that ...  positive   \n",
              "1      a wonderful little production. <br /><br />the...  positive   \n",
              "2      i thought this was a wonderful way to spend ti...  positive   \n",
              "3      basically there's a family where a little boy ...  negative   \n",
              "4      petter mattei's \"love in the time of money\" is...  positive   \n",
              "...                                                  ...       ...   \n",
              "49995  i thought this movie did a down right good job...  positive   \n",
              "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
              "49997  i am a catholic taught in parochial elementary...  negative   \n",
              "49998  i'm going to have to disagree with the previou...  negative   \n",
              "49999  no one expects the star trek movies to be high...  negative   \n",
              "\n",
              "                                review without stopwords  \\\n",
              "0      one reviewers mentioned watching just 1 oz epi...   \n",
              "1      wonderful little production. <br /><br />the f...   \n",
              "2      thought wonderful way spend time hot summer we...   \n",
              "3      basically family little boy (jake) thinks zomb...   \n",
              "4      petter mattei's \"love time money\" visually stu...   \n",
              "...                                                  ...   \n",
              "49995  thought movie right good job. wasn't creative ...   \n",
              "49996  bad plot, bad dialogue, bad acting, idiotic di...   \n",
              "49997  catholic taught parochial elementary schools n...   \n",
              "49998  going disagree previous comment side maltin on...   \n",
              "49999  no one expects star trek movies high art, fans...   \n",
              "\n",
              "                                            clean_review  sentiment score  \\\n",
              "0      one reviewers mentioned watching just 1 oz epi...         0.816103   \n",
              "1      wonderful little production  the filming techn...         0.982594   \n",
              "2      thought wonderful way spend time hot summer we...         0.981700   \n",
              "3      basically family little boy  jake  thinks zomb...         0.557990   \n",
              "4      petter mattei s  love time money  visually stu...         0.978383   \n",
              "...                                                  ...              ...   \n",
              "49995  thought movie right good job  wasn t creative ...         0.973569   \n",
              "49996  bad plot  bad dialogue  bad acting  idiotic di...         0.006047   \n",
              "49997  catholic taught parochial elementary schools n...         0.255125   \n",
              "49998  going disagree previous comment side maltin on...         0.224971   \n",
              "49999  no one expects star trek movies high art  fans...         0.192421   \n",
              "\n",
              "      predicted sentiment  \n",
              "0                positive  \n",
              "1                positive  \n",
              "2                positive  \n",
              "3                positive  \n",
              "4                positive  \n",
              "...                   ...  \n",
              "49995            positive  \n",
              "49996            negative  \n",
              "49997            negative  \n",
              "49998            negative  \n",
              "49999            negative  \n",
              "\n",
              "[50000 rows x 6 columns]"
            ]
          },
          "execution_count": 533,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {
        "id": "TTnm3Kwt4F0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95.204 %\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for i in range(len(dataf1)):\n",
        "    if dataf1.at[i, \"sentiment\"] == dataf1.at[i, \"predicted sentiment\"]:\n",
        "        count += 1\n",
        "print(count/len(dataf1)*100, \"%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "bloque nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 535,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95.828 %\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for i in range(len(dataf2)):\n",
        "    if dataf2.at[i, \"sentiment\"] == dataf2.at[i, \"predicted sentiment\"]:\n",
        "        count += 1\n",
        "print(count/len(dataf2)*100, \"%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN8YROakXxrOb1n93WZscH7",
      "mount_file_id": "1C5dKYAPz6GdYTLQLWAFzi4QcrKVO2o8A",
      "name": "IMDb_Movie_Sentiment_Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
